{"cells":[{"cell_type":"markdown","metadata":{},"source":["**This notebook is an exercise in the [SQL](https://www.kaggle.com/learn/intro-to-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/dansbecker/select-from-where).**\n","\n","---\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# %pip install google.cloud\n","# %pip install google-cloud-bigquery.\n","# %pip install learntools\n","# %pip install db-dtypes"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# %pip show google-cloud\n","# %pip show google-cloud-bigquery\n","# %pip show learntools\n","# %pip show db-dtypes"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import os\n","from google.cloud import bigquery\n","from dotenv import load_dotenv\n","\n","# Load environment variables from .env file\n","load_dotenv()\n","\n","# Load the path to the service account key file from the environment variable\n","keyfile_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n","\n","# Initialize BigQuery client with the service account key\n","client = bigquery.Client.from_service_account_json(keyfile_path)\n","\n","# Now you can use the `client` object to interact with BigQuery"]},{"cell_type":"markdown","metadata":{},"source":["# Introduction\n","\n","Try writing some **SELECT** statements of your own to explore a large dataset of air pollution measurements.\n","\n","Run the cell below to set up the feedback system."]},{"cell_type":"markdown","metadata":{},"source":["The code cell below fetches the `global_air_quality` table from the `openaq` dataset.  We also preview the first five rows of the table."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>location</th>\n","      <th>city</th>\n","      <th>country</th>\n","      <th>pollutant</th>\n","      <th>value</th>\n","      <th>timestamp</th>\n","      <th>unit</th>\n","      <th>source_name</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>averaged_over_in_hours</th>\n","      <th>location_geom</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Borówiec, ul. Drapałka</td>\n","      <td>Borówiec</td>\n","      <td>PL</td>\n","      <td>bc</td>\n","      <td>0.85217</td>\n","      <td>2022-04-28 07:00:00+00:00</td>\n","      <td>µg/m³</td>\n","      <td>GIOS</td>\n","      <td>1.0</td>\n","      <td>52.276794</td>\n","      <td>17.074114</td>\n","      <td>POINT(52.276794 1)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Kraków, ul. Bulwarowa</td>\n","      <td>Kraków</td>\n","      <td>PL</td>\n","      <td>bc</td>\n","      <td>0.91284</td>\n","      <td>2022-04-27 23:00:00+00:00</td>\n","      <td>µg/m³</td>\n","      <td>GIOS</td>\n","      <td>1.0</td>\n","      <td>50.069308</td>\n","      <td>20.053492</td>\n","      <td>POINT(50.069308 1)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Płock, ul. Reja</td>\n","      <td>Płock</td>\n","      <td>PL</td>\n","      <td>bc</td>\n","      <td>1.41000</td>\n","      <td>2022-03-30 04:00:00+00:00</td>\n","      <td>µg/m³</td>\n","      <td>GIOS</td>\n","      <td>1.0</td>\n","      <td>52.550938</td>\n","      <td>19.709791</td>\n","      <td>POINT(52.550938 1)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Elbląg, ul. Bażyńskiego</td>\n","      <td>Elbląg</td>\n","      <td>PL</td>\n","      <td>bc</td>\n","      <td>0.33607</td>\n","      <td>2022-05-03 13:00:00+00:00</td>\n","      <td>µg/m³</td>\n","      <td>GIOS</td>\n","      <td>1.0</td>\n","      <td>54.167847</td>\n","      <td>19.410942</td>\n","      <td>POINT(54.167847 1)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Piastów, ul. Pułaskiego</td>\n","      <td>Piastów</td>\n","      <td>PL</td>\n","      <td>bc</td>\n","      <td>0.51000</td>\n","      <td>2022-05-11 05:00:00+00:00</td>\n","      <td>µg/m³</td>\n","      <td>GIOS</td>\n","      <td>1.0</td>\n","      <td>52.191728</td>\n","      <td>20.837489</td>\n","      <td>POINT(52.191728 1)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  location      city country pollutant    value  \\\n","0   Borówiec, ul. Drapałka  Borówiec      PL        bc  0.85217   \n","1    Kraków, ul. Bulwarowa    Kraków      PL        bc  0.91284   \n","2          Płock, ul. Reja     Płock      PL        bc  1.41000   \n","3  Elbląg, ul. Bażyńskiego    Elbląg      PL        bc  0.33607   \n","4  Piastów, ul. Pułaskiego   Piastów      PL        bc  0.51000   \n","\n","                  timestamp   unit source_name  latitude  longitude  \\\n","0 2022-04-28 07:00:00+00:00  µg/m³        GIOS       1.0  52.276794   \n","1 2022-04-27 23:00:00+00:00  µg/m³        GIOS       1.0  50.069308   \n","2 2022-03-30 04:00:00+00:00  µg/m³        GIOS       1.0  52.550938   \n","3 2022-05-03 13:00:00+00:00  µg/m³        GIOS       1.0  54.167847   \n","4 2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  52.191728   \n","\n","   averaged_over_in_hours       location_geom  \n","0               17.074114  POINT(52.276794 1)  \n","1               20.053492  POINT(50.069308 1)  \n","2               19.709791  POINT(52.550938 1)  \n","3               19.410942  POINT(54.167847 1)  \n","4               20.837489  POINT(52.191728 1)  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from google.cloud import bigquery\n","\n","# Create a \"Client\" object\n","client = bigquery.Client()\n","\n","# Construct a reference to the \"openaq\" dataset\n","dataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n","\n","# API request - fetch the dataset\n","dataset = client.get_dataset(dataset_ref)\n","\n","# Construct a reference to the \"global_air_quality\" table\n","table_ref = dataset_ref.table(\"global_air_quality\")\n","\n","# API request - fetch the table\n","table = client.get_table(table_ref)\n","\n","# Preview the first five lines of the \"global_air_quality\" table\n","client.list_rows(table, max_results=5).to_dataframe()"]},{"cell_type":"markdown","metadata":{},"source":["# Exercises\n","\n","### 1) Units of measurement\n","\n","Which countries have reported pollution levels in units of \"ppm\"?  In the code cell below, set `first_query` to an SQL query that pulls the appropriate entries from the `country` column.\n","\n","In case it's useful to see an example query, here's some code from the tutorial:\n","\n","```\n","query = \"\"\"\n","        SELECT city\n","        FROM `bigquery-public-data.openaq.global_air_quality`\n","        WHERE country = 'US'\n","        \"\"\"\n","```"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"Forbidden","evalue":"403 POST https://bigquery.googleapis.com/bigquery/v2/projects/arboreal-timer-409911/jobs?prettyPrint=false: Access Denied: Project arboreal-timer-409911: User does not have bigquery.jobs.create permission in project arboreal-timer-409911.\n\nLocation: None\nJob ID: ce2146a3-7ac5-4ae4-88fb-4700b0fa6c54\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Set up the query (cancel the query if it would use too much of \u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# your quota, with the limit set to 10 GB)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m safe_config \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mQueryJobConfig(maximum_bytes_billed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m first_query_job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(first_query, job_config\u001b[38;5;241m=\u001b[39msafe_config)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# API request - run the query, and return a pandas DataFrame\u001b[39;00m\n\u001b[0;32m     14\u001b[0m first_results \u001b[38;5;241m=\u001b[39m first_query_job\u001b[38;5;241m.\u001b[39mto_dataframe()\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:3387\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[0;32m   3376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_query(\n\u001b[0;32m   3377\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3378\u001b[0m         query,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3384\u001b[0m         job_retry,\n\u001b[0;32m   3385\u001b[0m     )\n\u001b[0;32m   3386\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mQueryApiMethod\u001b[38;5;241m.\u001b[39mINSERT:\n\u001b[1;32m-> 3387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_insert(\n\u001b[0;32m   3388\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3389\u001b[0m         query,\n\u001b[0;32m   3390\u001b[0m         job_config,\n\u001b[0;32m   3391\u001b[0m         job_id,\n\u001b[0;32m   3392\u001b[0m         job_id_prefix,\n\u001b[0;32m   3393\u001b[0m         location,\n\u001b[0;32m   3394\u001b[0m         project,\n\u001b[0;32m   3395\u001b[0m         retry,\n\u001b[0;32m   3396\u001b[0m         timeout,\n\u001b[0;32m   3397\u001b[0m         job_retry,\n\u001b[0;32m   3398\u001b[0m     )\n\u001b[0;32m   3399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected value for api_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(api_method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:158\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[1;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m query_job\n\u001b[1;32m--> 158\u001b[0m future \u001b[38;5;241m=\u001b[39m do_query()\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# point, we may retry.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_id_given:\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:135\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m query_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mQueryJob(job_ref, query, client\u001b[38;5;241m=\u001b[39mclient, job_config\u001b[38;5;241m=\u001b[39mjob_config)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     query_job\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core_exceptions\u001b[38;5;241m.\u001b[39mConflict \u001b[38;5;28;01mas\u001b[39;00m create_exc:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job_id_given:\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1379\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m \n\u001b[0;32m   1361\u001b[0m \u001b[38;5;124;03mSee\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1379\u001b[0m     \u001b[38;5;28msuper\u001b[39m(QueryJob, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_begin(client\u001b[38;5;241m=\u001b[39mclient, retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1381\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1382\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[0;32m   1383\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\base.py:723\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[1;32m--> 723\u001b[0m api_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_call_api(\n\u001b[0;32m    724\u001b[0m     retry,\n\u001b[0;32m    725\u001b[0m     span_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigQuery.job.begin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    726\u001b[0m     span_attributes\u001b[38;5;241m=\u001b[39mspan_attributes,\n\u001b[0;32m    727\u001b[0m     job_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    728\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    729\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    730\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_api_repr(),\n\u001b[0;32m    731\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    732\u001b[0m )\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:818\u001b[0m, in \u001b[0;36mClient._call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[0;32m    816\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[0;32m    817\u001b[0m     ):\n\u001b[1;32m--> 818\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m call()\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry.py:372\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    371\u001b[0m )\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    373\u001b[0m     target,\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    375\u001b[0m     sleep_generator,\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    377\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    378\u001b[0m )\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    209\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n","\u001b[1;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/arboreal-timer-409911/jobs?prettyPrint=false: Access Denied: Project arboreal-timer-409911: User does not have bigquery.jobs.create permission in project arboreal-timer-409911.\n\nLocation: None\nJob ID: ce2146a3-7ac5-4ae4-88fb-4700b0fa6c54\n"]}],"source":["# Query to select countries with units of \"ppm\"\n","first_query = \"\"\"\n","    SELECT country\n","    FROM `bigquery-public-data.openaq.global_air_quality`\n","    WHERE unit = 'ppm'\n","\"\"\"\n","\n","# Set up the query (cancel the query if it would use too much of \n","# your quota, with the limit set to 10 GB)\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n","first_query_job = client.query(first_query, job_config=safe_config)\n","\n","# API request - run the query, and return a pandas DataFrame\n","first_results = first_query_job.to_dataframe()\n","\n","# View top few rows of results\n","print(first_results.head())"]},{"cell_type":"markdown","metadata":{},"source":["### 2) High air quality\n","\n","Which pollution levels were reported to be exactly 0?  \n","- Set `zero_pollution_query` to select **all columns** of the rows where the `value` column is 0.\n","- Set `zero_pollution_results` to a pandas DataFrame containing the query results."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"Forbidden","evalue":"403 POST https://bigquery.googleapis.com/bigquery/v2/projects/arboreal-timer-409911/jobs?prettyPrint=false: Access Denied: Project arboreal-timer-409911: User does not have bigquery.jobs.create permission in project arboreal-timer-409911.\n\nLocation: None\nJob ID: 043fc65b-c0fa-48cd-8d68-a2a80297d557\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Set up the query\u001b[39;00m\n\u001b[0;32m      9\u001b[0m safe_config \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mQueryJobConfig(maximum_bytes_billed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m query_job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(zero_pollution_query, job_config\u001b[38;5;241m=\u001b[39msafe_config)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# API request - run the query and return a pandas DataFrame\u001b[39;00m\n\u001b[0;32m     13\u001b[0m zero_pollution_results \u001b[38;5;241m=\u001b[39m query_job\u001b[38;5;241m.\u001b[39mto_dataframe()\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:3387\u001b[0m, in \u001b[0;36mClient.query\u001b[1;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry, api_method)\u001b[0m\n\u001b[0;32m   3376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_query(\n\u001b[0;32m   3377\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3378\u001b[0m         query,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3384\u001b[0m         job_retry,\n\u001b[0;32m   3385\u001b[0m     )\n\u001b[0;32m   3386\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m api_method \u001b[38;5;241m==\u001b[39m enums\u001b[38;5;241m.\u001b[39mQueryApiMethod\u001b[38;5;241m.\u001b[39mINSERT:\n\u001b[1;32m-> 3387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _job_helpers\u001b[38;5;241m.\u001b[39mquery_jobs_insert(\n\u001b[0;32m   3388\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3389\u001b[0m         query,\n\u001b[0;32m   3390\u001b[0m         job_config,\n\u001b[0;32m   3391\u001b[0m         job_id,\n\u001b[0;32m   3392\u001b[0m         job_id_prefix,\n\u001b[0;32m   3393\u001b[0m         location,\n\u001b[0;32m   3394\u001b[0m         project,\n\u001b[0;32m   3395\u001b[0m         retry,\n\u001b[0;32m   3396\u001b[0m         timeout,\n\u001b[0;32m   3397\u001b[0m         job_retry,\n\u001b[0;32m   3398\u001b[0m     )\n\u001b[0;32m   3399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected value for api_method: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(api_method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:158\u001b[0m, in \u001b[0;36mquery_jobs_insert\u001b[1;34m(client, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m query_job\n\u001b[1;32m--> 158\u001b[0m future \u001b[38;5;241m=\u001b[39m do_query()\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# point, we may retry.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m job_id_given:\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\_job_helpers.py:135\u001b[0m, in \u001b[0;36mquery_jobs_insert.<locals>.do_query\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m query_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mQueryJob(job_ref, query, client\u001b[38;5;241m=\u001b[39mclient, job_config\u001b[38;5;241m=\u001b[39mjob_config)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     query_job\u001b[38;5;241m.\u001b[39m_begin(retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core_exceptions\u001b[38;5;241m.\u001b[39mConflict \u001b[38;5;28;01mas\u001b[39;00m create_exc:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job_id_given:\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1379\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"API call:  begin the job via a POST request\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m \n\u001b[0;32m   1361\u001b[0m \u001b[38;5;124;03mSee\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    ValueError: If the job has already begun.\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1379\u001b[0m     \u001b[38;5;28msuper\u001b[39m(QueryJob, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_begin(client\u001b[38;5;241m=\u001b[39mclient, retry\u001b[38;5;241m=\u001b[39mretry, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m   1380\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mGoogleAPICallError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1381\u001b[0m     exc\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m=\u001b[39m _EXCEPTION_FOOTER_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1382\u001b[0m         message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mmessage, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation, job_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_id\n\u001b[0;32m   1383\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\job\\base.py:723\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[1;34m(self, client, retry, timeout)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;66;03m# jobs.insert is idempotent because we ensure that every new\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;66;03m# job has an ID.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[1;32m--> 723\u001b[0m api_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_call_api(\n\u001b[0;32m    724\u001b[0m     retry,\n\u001b[0;32m    725\u001b[0m     span_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBigQuery.job.begin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    726\u001b[0m     span_attributes\u001b[38;5;241m=\u001b[39mspan_attributes,\n\u001b[0;32m    727\u001b[0m     job_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    728\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    729\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    730\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_api_repr(),\n\u001b[0;32m    731\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    732\u001b[0m )\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_properties(api_response)\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\bigquery\\client.py:818\u001b[0m, in \u001b[0;36mClient._call_api\u001b[1;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[0;32m    816\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[0;32m    817\u001b[0m     ):\n\u001b[1;32m--> 818\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m call()\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry.py:372\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    369\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    371\u001b[0m )\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    373\u001b[0m     target,\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    375\u001b[0m     sleep_generator,\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    377\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    378\u001b[0m )\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry.py:207\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    209\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n","File \u001b[1;32mc:\\Users\\aga\\anaconda3\\Lib\\site-packages\\google\\cloud\\_http\\__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[1;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[0;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n","\u001b[1;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/arboreal-timer-409911/jobs?prettyPrint=false: Access Denied: Project arboreal-timer-409911: User does not have bigquery.jobs.create permission in project arboreal-timer-409911.\n\nLocation: None\nJob ID: 043fc65b-c0fa-48cd-8d68-a2a80297d557\n"]}],"source":["# Query to select all columns where pollution levels are exactly 0\n","zero_pollution_query = \"\"\"\n","    SELECT *\n","    FROM `bigquery-public-data.openaq.global_air_quality`\n","    WHERE value = 0\n","\"\"\"\n","\n","# Set up the query\n","safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n","query_job = client.query(zero_pollution_query, job_config=safe_config)\n","\n","# API request - run the query and return a pandas DataFrame\n","zero_pollution_results = query_job.to_dataframe()\n","\n","print(zero_pollution_results.head())"]},{"cell_type":"markdown","metadata":{},"source":["That query wasn't too complicated, and it got the data you want. But these **SELECT** queries don't organizing data in a way that answers the most interesting questions. For that, we'll need the **GROUP BY** command. \n","\n","If you know how to use [`groupby()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) in pandas, this is similar. But BigQuery works quickly with far larger datasets.\n","\n","Fortunately, that's next."]},{"cell_type":"markdown","metadata":{},"source":["# Keep going\n","**[GROUP BY](https://www.kaggle.com/dansbecker/group-by-having-count)** clauses and their extensions give you the power to pull interesting statistics out of data, rather than receiving it in just its raw format."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","\n","\n","\n","*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-sql/discussion) to chat with other learners.*"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5836,"sourceId":8677,"sourceType":"datasetVersion"},{"datasetId":6057,"sourceId":285982,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
